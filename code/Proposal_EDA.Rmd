---
title: "Project Proposal (Code for EDA)"
author: "Marshmallow"
date: "2022 3 9"
output:
  pdf_document: default
  html_document:
    df_print: paged
header-includes:
  \usepackage{fvextra}
  \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if(!require(stringr)) { install.packages("stringr", repos = "http://cran.us.r-project.org"); library(stringr) }
if(!require(base)) { install.packages("base", repos = "http://cran.us.r-project.org"); library(base) }
if(!require(tm)) { install.packages("tm", repos = "http://cran.us.r-project.org"); library(tm) }
if(!require(ggplot2)) { install.packages("ggplot2", repos = "http://cran.us.r-project.org"); library(ggplot2) }
if(!require(RColorBrewer)) { install.packages("RColorBrewer", repos = "http://cran.us.r-project.org"); library(RColorBrewer) }
if(!require(ggpubr)) { install.packages("ggpubr", repos = "http://cran.us.r-project.org"); library(ggpubr) }
if(!require(dplyr)) { install.packages("dplyr", repos = "http://cran.us.r-project.org"); library(dplyr) }
if(!require(GGally)) { install.packages("GGally", repos = "http://cran.us.r-project.org"); library(GGally) }
```

```{r wrap-hook, echo=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
```

## 1. Data Pre-processing and Cleaning
### 1-1. Data Pre-processing
```{r preprocessing, linewidth = 90}
# 1. Read Data
df.fake <- read.csv('../data/Fake.csv', encoding = 'UTF-8', 
                    header = TRUE)
df.true <- read.csv('../data/True.csv', encoding = 'UTF-8', 
                    header = TRUE)

# 2. Look through the data
          # dimension
dim(df.fake)
dim(df.true)
          # check NA values
table(is.na(df.fake))
table(is.na(df.true))
          # simple view of the data
colnames(df.fake)
colnames(df.true)
head(df.fake, 1)
head(df.true, 1)
          # category table of the data
table(df.fake$subject)
table(df.true$subject)
```

### 1-2. Data Cleaning
```{r data_cleaning_1, linewidth = 90}
# 1. Remove redundant strings
          # Average text containing "(Reuters)" in True v. Fake Dataset
mean(grepl("(Reuters)", df.fake$text, fixed = TRUE))
mean(grepl("(Reuters)", df.true$text, fixed = TRUE))
          # Drop Prefix (Reuters) Function
drop_prefix <- function(text, prefix = '(Reuters)', n = 5) {
          # splits textual data into separate words + symbols
          ts = strsplit(text, " ") 
          ifelse(prefix %in% ts[[1]][1:5], 
                 strsplit(text,"(Reuters) - ", fixed = TRUE)[[1]][-1], text)
}
new_Text <- apply(df.true["text"], 1, drop_prefix)
new_Text <- as.data.frame(new_Text)
df.true["text"] <- new_Text
          # result
df.true$text[1]
```

```{r data_cleaning_2, eval=FALSE, echo=TRUE}
# 2. Combine Data
df.fake$Class <- 0
df.true$Class <- 1
df.full<- rbind(df.fake, df.true)
          # give column names which are missing
colnames(df.full) <- c("Title", "MainText", "Subject", "Date", "Class")
colnames(df.full)

# 3. Clean up Data
df.full$Title <- gsub("[][!#$%()*,.:;<=>@^_|~.{}]", " ", df.full$Title)
df.full$Title <- gsub("‘|’|“|”|–", " ", df.full$Title)

df.full$MainText <- gsub("[][!#$%()*,.:;<=>@^_|~.{}]", " ", df.full$MainText)
df.full$MainText <- gsub("‘|’|“|”|–", " ", df.full$MainText)
          # Save the result
write.csv(df.full, "../data/Full.csv", row.names = FALSE)
```

```{r cleaning_result, linewidth = 90}
# 1. Read the saved data
df.full <- read.csv("../data/Full.csv", encoding = 'UTF-8',
                    header = TRUE)
df.full$Class <- as.factor(df.full$Class)

# 2. Check null data
table(is.na(df.full))

# 3. Split the data
df.split <- split(df.full, f = df.full$Class)
df.fake <- df.split[['0']]
df.true <- df.split[['1']]
```

## 2. Exploratory data analysis(EDA)

### 2-1. Word Count Distribution of Fake and True News
```{r EDA_histogram, message=FALSE, fig.width = 10}
hist.title <- df.full %>% 
                    mutate(WC.Title = str_count(Title, '\\w+')) %>% 
                    ggplot(aes(x = WC.Title, fill = Class, color = Class)) +
                    geom_histogram(position = 'dodge', alpha=0.5) +
                    scale_color_manual(values=c("#d96a5d", "#69b3a2")) +
                    scale_fill_manual(values=c("#d96a5d", "#69b3a2")) +
                    labs(title = "Histogram of word count: Title",
                         x ="Word count", y = "Frequency") +
                    theme(legend.position = "right")

hist.main <- df.full %>% 
                    mutate(WC.Main = str_count(MainText, '\\w+')) %>% 
                    ggplot(aes(x = WC.Main, fill = Class, color = Class)) +
                    geom_histogram(position = 'dodge', alpha=0.5) +
                    scale_color_manual(values=c("#d96a5d", "#69b3a2")) +
                    scale_fill_manual(values=c("#d96a5d", "#69b3a2")) +
                    labs(title = "Histogram of word count: Main text",
                         x ="Word count", y = "Frequency") +
                    theme(legend.position = "right")

ggarrange(hist.title, hist.main,  
          ncol = 2, nrow = 1)
```

### 2-2. Top 20 of most used word for Fake and True News
```{r EDA_freq_top20, eval=FALSE, echo=TRUE}
# 1. Data cleaning and calculate the word frequency
cleanup.text <- function(docs){
  toSpace <- content_transformer(function (x , pattern) gsub(pattern, " ", x))
    
  docs <- docs %>%
    tm_map(removeNumbers) %>%
    tm_map(removePunctuation) %>%
    tm_map(stripWhitespace) %>% 
    tm_map(content_transformer(tolower)) %>% 
    tm_map(toSpace, "/") %>% 
    tm_map(toSpace, "@") %>% 
    tm_map(toSpace, "\\|")
  docs <- tm_map(docs, removeWords, c("the"))
  docs <- tm_map(docs, removeWords, c("['’]s\b|[^[:alnum:][:blank:]@_]"))

  stopwords_regex <- paste(stopwords('en'), collapse = '\\b|\\b')
  stopwords_regex <- paste0('\\b', stopwords_regex, '\\b')
  docs <- str_replace_all(docs, stopwords_regex, '')
  docs <- Corpus(VectorSource(docs))
  doc_mat <- TermDocumentMatrix(docs)
  m <- as.matrix(doc_mat)
  v <- sort(rowSums(m), decreasing = TRUE)
  d_Rcran <- data.frame(word = names(v), freq = v)
  return(d_Rcran)
}

# 2. Save results of Title
          # Fake News
fake.title <- paste(df.fake$Title, collapse = " ")
docs <- Corpus(VectorSource(fake.title))
fake.title.freq <- cleanup.text(docs)
write.csv(fake.title.freq, "../data/Fake_wordFreq_Title.csv", row.names = FALSE)
          # True News
true.title <- paste(df.true$Title, collapse = " ")
docs <- Corpus(VectorSource(true.title))
true.title.freq <- cleanup.text(docs)
write.csv(true.title.freq, "../data/True_wordFreq_Title.csv", row.names = FALSE)

# 3. Save results of Main Text
          # Fake News
fake.MainText <- paste(df.fake$MainText, collapse = " ")
docs <- Corpus(VectorSource(fake.MainText))
fake.MainText.freq <- cleanup.text(docs)
write.csv(fake.MainText.freq, "../data/Fake_wordFreq_MainText.csv", row.names = FALSE)
          # True News
true.MainText <- paste(df.true$MainText, collapse = " ")
docs <- Corpus(VectorSource(true.MainText))
true.MainText.freq <- cleanup.text(docs)
write.csv(true.MainText.freq, "../data/True_wordFreq_MainText.csv", row.names = FALSE)
```

```{r EDA_barplot, fig.width = 10, fig.height=6}
# 1. Read frequency data for title
df.fakeTitle.freq <- read.csv('../data/Fake_wordFreq_Title.csv', encoding = 'UTF-8', 
                    header = TRUE)
df.trueTitle.freq <- read.csv('../data/True_wordFreq_Title.csv', encoding = 'UTF-8',
                    header = TRUE)

# 2. Draw bar plot of top 20 for title
myColors <- brewer.pal(11, "Spectral")
fake.bar <- top_n(df.fakeTitle.freq, 20, freq) %>%
                    arrange(freq) %>%  
                    mutate(word = factor(word, levels = word)) %>% 
                    ggplot(aes(x = word, y = freq, fill = word)) + 
                    geom_bar(stat="identity") + 
                    scale_colour_manual(name = "word", values = myColors) +
                    labs(title = "Top 20 words: Fake(in Title)",
                                   x ="Word", y = "Frequency") +
                    coord_flip()

true.bar <- top_n(df.trueTitle.freq, 20, freq) %>%
                    arrange(freq) %>%  
                    mutate(word = factor(word, levels = word)) %>% 
                    ggplot(aes(x = word, y = freq, fill = word)) + 
                    geom_bar(stat="identity") + 
                    scale_colour_manual(name = "word", values = myColors) +
                    labs(title = "Top 20 words: True(in Title)",
                         x ="Word", y = "Frequency") +
                    coord_flip()

ggarrange(fake.bar, true.bar,  
          ncol = 2, nrow = 1)

# 3. Read frequency data for MainText
df.fakeMainText.freq <- read.csv('../data/Fake_wordFreq_MainText.csv', encoding = 'UTF-8', 
                    header = TRUE)
df.trueMainText.freq <- read.csv('../data/True_wordFreq_MainText.csv', encoding = 'UTF-8',
                    header = TRUE)

# 2. Draw bar plot of top 20 for MainText
myColors <- brewer.pal(11, "Spectral")
fake.bar <- top_n(df.fakeMainText.freq, 20, freq) %>%
                    arrange(freq) %>%  
                    mutate(word = factor(word, levels = word)) %>% 
                    ggplot(aes(x = word, y = freq, fill = word)) + 
                    geom_bar(stat="identity") + 
                    scale_colour_manual(name = "word", values = myColors) +
                    labs(title = "Top 20 words: Fake(in Main text)",
                                   x ="Word", y = "Frequency") +
                    coord_flip()

true.bar <- top_n(df.trueMainText.freq, 20, freq) %>%
                    arrange(freq) %>%  
                    mutate(word = factor(word, levels = word)) %>% 
                    ggplot(aes(x = word, y = freq, fill = word)) + 
                    geom_bar(stat="identity") + 
                    scale_colour_manual(name = "word", values = myColors) +
                    labs(title = "Top 20 words: True(in Main text)",
                         x ="Word", y = "Frequency") +
                    coord_flip()

ggarrange(fake.bar, true.bar,  
          ncol = 2, nrow = 1)
```

## 3. EDA of Linguistic Inquiry and Word Count(LIWC) data

### 3-1. Pre-processing LIWC Result
```{r LIWC_preprocessing, linewidth = 90}
# 1. Read Data
df.fake.LIWC <- read.csv('../data/565_Fake_LIWC.csv', encoding = 'UTF-8', 
                    header = TRUE)
df.true.LIWC <- read.csv('../data/565_True_LIWC.csv', encoding = 'UTF-8',
                    header = TRUE)

# 2. Combine Data
df.fake.LIWC$Class <- 0
df.true.LIWC$Class <- 1
df.full.LIWC <- rbind(df.fake.LIWC, df.true.LIWC)
df.full.LIWC$Class <- as.factor(df.full.LIWC$Class)
          # give column names which are missing
colnames(df.full.LIWC)[1:4] <- c("Title", "MainText", "Category", "Date")
colnames(df.full.LIWC)

# 3. Clean up Data
df.full.LIWC$Title <- gsub("[][!#$%()*,.:;<=>@^_|~.{}]", " ", df.full.LIWC$Title)
df.full.LIWC$Title <- gsub("‘|’|“|”|–", " ", df.full.LIWC$Title)

df.full.LIWC$MainText <- gsub("[][!#$%()*,.:;<=>@^_|~.{}]", " ", df.full.LIWC$MainText)
df.full.LIWC$MainText <- gsub("‘|’|“|”|–", " ", df.full.LIWC$MainText)

# 4. Look through the data
          # dimension
dim(df.full.LIWC)
          # check NA values
table(is.na(df.full.LIWC))
          # simple view of the data
head(df.full.LIWC, 1)
```

### 3-2. Correlations between LIWC Variables
```{r LIWC_cor, linewidth = 90}
# 1. Select upper-level variables
top_var <- c("Class", "WC", "Tone", "WPS", "Sixltr", "function.", "ppron", 
             "article", "prep", "auxverb", "adverb", "conj", "negate", "verb", 
             "adj", "interrog", "quant", "affect", "social", "cogproc", 
             "percept", "bio", "drives", "relativ", "work", "leisure", "home", 
             "money", "relig", "death", "informal")

# 2. Build correlation table
df.full.LIWC.top <- df.full.LIWC[, top_var]
df.full.LIWC.top$Class <- as.numeric(df.full.LIWC.top$Class)
LIWC.cor <- cor(df.full.LIWC.top)
head(round(LIWC.cor, 3), 10)

# 3. Show first 20 biggest correlation (in absolute value)
LIWC.cor[lower.tri(LIWC.cor, diag=TRUE)] <- 0  
LIWC.cor.sorted <- sort(abs(LIWC.cor), decreasing=T)
LIWC.cor.top20 <- data.frame()
for (val in 1:20){
  vars.big.cor <- arrayInd(which(abs(LIWC.cor) == LIWC.cor.sorted[val]), 
                        dim(LIWC.cor)) 
  LIWC.cor.top20 <- rbind(LIWC.cor.top20, 
                          c(colnames(df.full.LIWC.top)[vars.big.cor], 
                            round(LIWC.cor.sorted[val], 3)))
}
colnames(LIWC.cor.top20) <- c("Var1", "Var2", "Correlation")
LIWC.cor.top20
```

### 3-3. Visualizing Relationships among LIWC variables
```{r LIWC_scatter, message=FALSE, fig.width = 10}
df.subfull.LIWC <- df.full.LIWC %>% 
          select("Class", "WC", "WPS", "Tone", "ppron", "Sixltr", "adverb", 
                 "social", "informal")
ggpairs(df.subfull.LIWC)
```

```{r LIWC_boxplot, fig.width = 10}
par(mfrow=c(2,4))
boxplot(df.subfull.LIWC$Class, df.subfull.LIWC$WC, main="WC versus Class",
     xlab="0 = Fake, 1 = True", ylab="WC")
boxplot(df.subfull.LIWC$Class, df.subfull.LIWC$WPS, main="WPS versus Class",
     xlab="0 = Fake, 1 = True", ylab="WPS")
boxplot(df.subfull.LIWC$Class, df.subfull.LIWC$Tone, main="Tone versus Class",
     xlab="0 = Fake, 1 = True", ylab="Tone")
boxplot(df.subfull.LIWC$Class, df.subfull.LIWC$ppron, main="ppron versus Class",
     xlab="0 = Fake, 1 = True", ylab="ppron")
boxplot(df.subfull.LIWC$Class, df.subfull.LIWC$Sixltr, main="Sixltr versus Class",
     xlab="0 = Fake, 1 = True", ylab="Sixltr")
boxplot(df.subfull.LIWC$Class, df.subfull.LIWC$adverb, main="adverb versus Class",
     xlab="0 = Fake, 1 = True", ylab="adverb")
boxplot(df.subfull.LIWC$Class, df.subfull.LIWC$social, main="social versus Class",
     xlab="0 = Fake, 1 = True", ylab="social")
boxplot(df.subfull.LIWC$Class, df.subfull.LIWC$informal, main="informal versus Class",
     xlab="0 = Fake, 1 = True", ylab="informal")
par(mfrow=c(1,1))
```

### 3-4. Testing means between two different groups
```{r LIWC_ttest, linewidth = 90}
t.test(df.subfull.LIWC$WC[df.subfull.LIWC$Class==0],
       df.subfull.LIWC$WC[df.subfull.LIWC$Class==1])
t.test(df.subfull.LIWC$WPS[df.subfull.LIWC$Class==0],
       df.subfull.LIWC$WPS[df.subfull.LIWC$Class==1])
t.test(df.subfull.LIWC$Tone[df.subfull.LIWC$Class==0],
       df.subfull.LIWC$Tone[df.subfull.LIWC$Class==1])
t.test(df.subfull.LIWC$ppron[df.subfull.LIWC$Class==0],
       df.subfull.LIWC$ppron[df.subfull.LIWC$Class==1])
t.test(df.subfull.LIWC$social[df.subfull.LIWC$Class==0],
       df.subfull.LIWC$social[df.subfull.LIWC$Class==1])
t.test(df.subfull.LIWC$adverb[df.subfull.LIWC$Class==0],
       df.subfull.LIWC$adverb[df.subfull.LIWC$Class==1])
t.test(df.subfull.LIWC$Sixltr[df.subfull.LIWC$Class==0],
       df.subfull.LIWC$Sixltr[df.subfull.LIWC$Class==1])
t.test(df.subfull.LIWC$informal[df.subfull.LIWC$Class==0],
       df.subfull.LIWC$informal[df.subfull.LIWC$Class==1])
```
